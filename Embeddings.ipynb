{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chroma_client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m collection \u001b[38;5;241m=\u001b[39m \u001b[43mchroma_client\u001b[49m\u001b[38;5;241m.\u001b[39mdelete_collection(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlecture_notes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chroma_client' is not defined"
     ]
    }
   ],
   "source": [
    "collection = chroma_client.delete_collection(\"lecture_notes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from getpass import getpass\n",
    "from langchain_chroma import Chroma\n",
    "import json\n",
    "import re\n",
    "import chromadb\n",
    "import os\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from chromadb.config import Settings\n",
    "\n",
    "OPENAI_API_KEY=\"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\"\n",
    "openai.api_key=OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insert of existing embedding ID: 0\n",
      "Add of existing embedding ID: 0\n",
      "Insert of existing embedding ID: 1\n",
      "Add of existing embedding ID: 1\n",
      "Insert of existing embedding ID: 2\n",
      "Add of existing embedding ID: 2\n",
      "Insert of existing embedding ID: 3\n",
      "Add of existing embedding ID: 3\n",
      "Insert of existing embedding ID: 4\n",
      "Add of existing embedding ID: 4\n",
      "Insert of existing embedding ID: 5\n",
      "Add of existing embedding ID: 5\n",
      "Insert of existing embedding ID: 6\n",
      "Add of existing embedding ID: 6\n",
      "Insert of existing embedding ID: 7\n",
      "Add of existing embedding ID: 7\n",
      "Insert of existing embedding ID: 8\n",
      "Add of existing embedding ID: 8\n",
      "Insert of existing embedding ID: 9\n",
      "Add of existing embedding ID: 9\n",
      "Insert of existing embedding ID: 10\n",
      "Add of existing embedding ID: 10\n",
      "Insert of existing embedding ID: 11\n",
      "Add of existing embedding ID: 11\n",
      "Insert of existing embedding ID: 12\n",
      "Add of existing embedding ID: 12\n",
      "Insert of existing embedding ID: 13\n",
      "Add of existing embedding ID: 13\n",
      "Insert of existing embedding ID: 14\n",
      "Add of existing embedding ID: 14\n",
      "Insert of existing embedding ID: 15\n",
      "Add of existing embedding ID: 15\n",
      "Insert of existing embedding ID: 16\n",
      "Add of existing embedding ID: 16\n",
      "Insert of existing embedding ID: 17\n",
      "Add of existing embedding ID: 17\n",
      "Insert of existing embedding ID: 18\n",
      "Add of existing embedding ID: 18\n",
      "Insert of existing embedding ID: 19\n",
      "Add of existing embedding ID: 19\n",
      "Insert of existing embedding ID: 20\n",
      "Add of existing embedding ID: 20\n",
      "Insert of existing embedding ID: 21\n",
      "Add of existing embedding ID: 21\n",
      "Insert of existing embedding ID: 22\n",
      "Add of existing embedding ID: 22\n",
      "Insert of existing embedding ID: 23\n",
      "Add of existing embedding ID: 23\n",
      "Insert of existing embedding ID: 24\n",
      "Add of existing embedding ID: 24\n",
      "Insert of existing embedding ID: 25\n",
      "Add of existing embedding ID: 25\n",
      "Insert of existing embedding ID: 26\n",
      "Add of existing embedding ID: 26\n",
      "Insert of existing embedding ID: 27\n",
      "Add of existing embedding ID: 27\n",
      "Insert of existing embedding ID: 28\n",
      "Add of existing embedding ID: 28\n",
      "Insert of existing embedding ID: 29\n",
      "Add of existing embedding ID: 29\n",
      "Insert of existing embedding ID: 30\n",
      "Add of existing embedding ID: 30\n",
      "Insert of existing embedding ID: 31\n",
      "Add of existing embedding ID: 31\n",
      "Insert of existing embedding ID: 32\n",
      "Add of existing embedding ID: 32\n",
      "Insert of existing embedding ID: 33\n",
      "Add of existing embedding ID: 33\n",
      "Insert of existing embedding ID: 34\n",
      "Add of existing embedding ID: 34\n",
      "Insert of existing embedding ID: 35\n",
      "Add of existing embedding ID: 35\n",
      "Insert of existing embedding ID: 36\n",
      "Add of existing embedding ID: 36\n",
      "Insert of existing embedding ID: 37\n",
      "Add of existing embedding ID: 37\n",
      "Insert of existing embedding ID: 38\n",
      "Add of existing embedding ID: 38\n",
      "Insert of existing embedding ID: 39\n",
      "Add of existing embedding ID: 39\n",
      "Insert of existing embedding ID: 40\n",
      "Add of existing embedding ID: 40\n",
      "Insert of existing embedding ID: 41\n",
      "Add of existing embedding ID: 41\n",
      "Insert of existing embedding ID: 42\n",
      "Add of existing embedding ID: 42\n",
      "Insert of existing embedding ID: 43\n",
      "Add of existing embedding ID: 43\n",
      "Insert of existing embedding ID: 44\n",
      "Add of existing embedding ID: 44\n",
      "Insert of existing embedding ID: 45\n",
      "Add of existing embedding ID: 45\n",
      "Insert of existing embedding ID: 46\n",
      "Add of existing embedding ID: 46\n",
      "Insert of existing embedding ID: 47\n",
      "Add of existing embedding ID: 47\n",
      "Insert of existing embedding ID: 48\n",
      "Add of existing embedding ID: 48\n",
      "Insert of existing embedding ID: 49\n",
      "Add of existing embedding ID: 49\n",
      "Insert of existing embedding ID: 50\n",
      "Add of existing embedding ID: 50\n",
      "Insert of existing embedding ID: 51\n",
      "Add of existing embedding ID: 51\n",
      "Insert of existing embedding ID: 52\n",
      "Add of existing embedding ID: 52\n",
      "Insert of existing embedding ID: 53\n",
      "Add of existing embedding ID: 53\n",
      "Insert of existing embedding ID: 54\n",
      "Add of existing embedding ID: 54\n",
      "Insert of existing embedding ID: 55\n",
      "Add of existing embedding ID: 55\n",
      "Insert of existing embedding ID: 56\n",
      "Add of existing embedding ID: 56\n",
      "Insert of existing embedding ID: 57\n",
      "Add of existing embedding ID: 57\n",
      "Insert of existing embedding ID: 58\n",
      "Add of existing embedding ID: 58\n",
      "Insert of existing embedding ID: 59\n",
      "Add of existing embedding ID: 59\n",
      "Insert of existing embedding ID: 60\n",
      "Add of existing embedding ID: 60\n",
      "Insert of existing embedding ID: 61\n",
      "Add of existing embedding ID: 61\n",
      "Insert of existing embedding ID: 62\n",
      "Add of existing embedding ID: 62\n",
      "Insert of existing embedding ID: 63\n",
      "Add of existing embedding ID: 63\n",
      "Insert of existing embedding ID: 64\n",
      "Add of existing embedding ID: 64\n",
      "Insert of existing embedding ID: 65\n",
      "Add of existing embedding ID: 65\n",
      "Insert of existing embedding ID: 66\n",
      "Add of existing embedding ID: 66\n",
      "Insert of existing embedding ID: 67\n",
      "Add of existing embedding ID: 67\n",
      "Insert of existing embedding ID: 68\n",
      "Add of existing embedding ID: 68\n",
      "Insert of existing embedding ID: 69\n",
      "Add of existing embedding ID: 69\n",
      "Insert of existing embedding ID: 70\n",
      "Add of existing embedding ID: 70\n",
      "Insert of existing embedding ID: 71\n",
      "Add of existing embedding ID: 71\n",
      "Insert of existing embedding ID: 72\n",
      "Add of existing embedding ID: 72\n",
      "Insert of existing embedding ID: 73\n",
      "Add of existing embedding ID: 73\n",
      "Insert of existing embedding ID: 74\n",
      "Add of existing embedding ID: 74\n",
      "Insert of existing embedding ID: 75\n",
      "Add of existing embedding ID: 75\n",
      "Insert of existing embedding ID: 76\n",
      "Add of existing embedding ID: 76\n",
      "Insert of existing embedding ID: 77\n",
      "Add of existing embedding ID: 77\n",
      "Insert of existing embedding ID: 78\n",
      "Add of existing embedding ID: 78\n",
      "Insert of existing embedding ID: 79\n",
      "Add of existing embedding ID: 79\n",
      "Insert of existing embedding ID: 80\n",
      "Add of existing embedding ID: 80\n",
      "Insert of existing embedding ID: 81\n",
      "Add of existing embedding ID: 81\n",
      "Insert of existing embedding ID: 82\n",
      "Add of existing embedding ID: 82\n",
      "Insert of existing embedding ID: 83\n",
      "Add of existing embedding ID: 83\n",
      "Insert of existing embedding ID: 84\n",
      "Add of existing embedding ID: 84\n",
      "Insert of existing embedding ID: 85\n",
      "Add of existing embedding ID: 85\n",
      "Insert of existing embedding ID: 86\n",
      "Add of existing embedding ID: 86\n",
      "Insert of existing embedding ID: 87\n",
      "Add of existing embedding ID: 87\n",
      "Insert of existing embedding ID: 88\n",
      "Add of existing embedding ID: 88\n",
      "Insert of existing embedding ID: 89\n",
      "Add of existing embedding ID: 89\n",
      "Insert of existing embedding ID: 90\n",
      "Add of existing embedding ID: 90\n",
      "Insert of existing embedding ID: 91\n",
      "Add of existing embedding ID: 91\n",
      "Insert of existing embedding ID: 92\n",
      "Add of existing embedding ID: 92\n",
      "Insert of existing embedding ID: 93\n",
      "Add of existing embedding ID: 93\n",
      "Insert of existing embedding ID: 94\n",
      "Add of existing embedding ID: 94\n",
      "Insert of existing embedding ID: 95\n",
      "Add of existing embedding ID: 95\n",
      "Insert of existing embedding ID: 96\n",
      "Add of existing embedding ID: 96\n",
      "Insert of existing embedding ID: 97\n",
      "Add of existing embedding ID: 97\n",
      "Insert of existing embedding ID: 98\n",
      "Add of existing embedding ID: 98\n",
      "Insert of existing embedding ID: 99\n",
      "Add of existing embedding ID: 99\n",
      "Insert of existing embedding ID: 100\n",
      "Add of existing embedding ID: 100\n",
      "Insert of existing embedding ID: 101\n",
      "Add of existing embedding ID: 101\n",
      "Insert of existing embedding ID: 102\n",
      "Add of existing embedding ID: 102\n",
      "Insert of existing embedding ID: 103\n",
      "Add of existing embedding ID: 103\n",
      "Insert of existing embedding ID: 104\n",
      "Add of existing embedding ID: 104\n",
      "Insert of existing embedding ID: 105\n",
      "Add of existing embedding ID: 105\n",
      "Insert of existing embedding ID: 106\n",
      "Add of existing embedding ID: 106\n",
      "Insert of existing embedding ID: 107\n",
      "Add of existing embedding ID: 107\n",
      "Insert of existing embedding ID: 108\n",
      "Add of existing embedding ID: 108\n",
      "Insert of existing embedding ID: 109\n",
      "Add of existing embedding ID: 109\n",
      "Insert of existing embedding ID: 110\n",
      "Add of existing embedding ID: 110\n",
      "Insert of existing embedding ID: 111\n",
      "Add of existing embedding ID: 111\n",
      "Insert of existing embedding ID: 112\n",
      "Add of existing embedding ID: 112\n",
      "Insert of existing embedding ID: 113\n",
      "Add of existing embedding ID: 113\n",
      "Insert of existing embedding ID: 114\n",
      "Add of existing embedding ID: 114\n",
      "Insert of existing embedding ID: 115\n",
      "Add of existing embedding ID: 115\n",
      "Insert of existing embedding ID: 116\n",
      "Add of existing embedding ID: 116\n",
      "Insert of existing embedding ID: 117\n",
      "Add of existing embedding ID: 117\n",
      "Insert of existing embedding ID: 118\n",
      "Add of existing embedding ID: 118\n",
      "Insert of existing embedding ID: 119\n",
      "Add of existing embedding ID: 119\n",
      "Insert of existing embedding ID: 120\n",
      "Add of existing embedding ID: 120\n",
      "Insert of existing embedding ID: 121\n",
      "Add of existing embedding ID: 121\n",
      "Insert of existing embedding ID: 122\n",
      "Add of existing embedding ID: 122\n",
      "Insert of existing embedding ID: 123\n",
      "Add of existing embedding ID: 123\n",
      "Insert of existing embedding ID: 124\n",
      "Add of existing embedding ID: 124\n",
      "Insert of existing embedding ID: 125\n",
      "Add of existing embedding ID: 125\n",
      "Insert of existing embedding ID: 126\n",
      "Add of existing embedding ID: 126\n",
      "Insert of existing embedding ID: 127\n",
      "Add of existing embedding ID: 127\n",
      "Insert of existing embedding ID: 128\n",
      "Add of existing embedding ID: 128\n",
      "Insert of existing embedding ID: 129\n",
      "Add of existing embedding ID: 129\n",
      "Insert of existing embedding ID: 130\n",
      "Add of existing embedding ID: 130\n",
      "Insert of existing embedding ID: 131\n",
      "Add of existing embedding ID: 131\n",
      "Insert of existing embedding ID: 132\n",
      "Add of existing embedding ID: 132\n",
      "Insert of existing embedding ID: 133\n",
      "Add of existing embedding ID: 133\n",
      "Insert of existing embedding ID: 134\n",
      "Add of existing embedding ID: 134\n",
      "Insert of existing embedding ID: 135\n",
      "Add of existing embedding ID: 135\n",
      "Insert of existing embedding ID: 136\n",
      "Add of existing embedding ID: 136\n",
      "Insert of existing embedding ID: 137\n",
      "Add of existing embedding ID: 137\n",
      "Insert of existing embedding ID: 138\n",
      "Add of existing embedding ID: 138\n",
      "Insert of existing embedding ID: 139\n",
      "Add of existing embedding ID: 139\n",
      "Insert of existing embedding ID: 140\n",
      "Add of existing embedding ID: 140\n",
      "Insert of existing embedding ID: 141\n",
      "Add of existing embedding ID: 141\n",
      "Insert of existing embedding ID: 142\n",
      "Add of existing embedding ID: 142\n",
      "Insert of existing embedding ID: 143\n",
      "Add of existing embedding ID: 143\n",
      "Insert of existing embedding ID: 144\n",
      "Add of existing embedding ID: 144\n",
      "Insert of existing embedding ID: 145\n",
      "Add of existing embedding ID: 145\n",
      "Insert of existing embedding ID: 146\n",
      "Add of existing embedding ID: 146\n",
      "Insert of existing embedding ID: 147\n",
      "Add of existing embedding ID: 147\n",
      "Insert of existing embedding ID: 148\n",
      "Add of existing embedding ID: 148\n",
      "Insert of existing embedding ID: 149\n",
      "Add of existing embedding ID: 149\n",
      "Insert of existing embedding ID: 150\n",
      "Add of existing embedding ID: 150\n",
      "Insert of existing embedding ID: 151\n",
      "Add of existing embedding ID: 151\n",
      "Insert of existing embedding ID: 152\n",
      "Add of existing embedding ID: 152\n",
      "Insert of existing embedding ID: 153\n",
      "Add of existing embedding ID: 153\n",
      "Insert of existing embedding ID: 154\n",
      "Add of existing embedding ID: 154\n",
      "Insert of existing embedding ID: 155\n",
      "Add of existing embedding ID: 155\n",
      "Insert of existing embedding ID: 156\n",
      "Add of existing embedding ID: 156\n",
      "Insert of existing embedding ID: 157\n",
      "Add of existing embedding ID: 157\n",
      "Insert of existing embedding ID: 158\n",
      "Add of existing embedding ID: 158\n",
      "Insert of existing embedding ID: 159\n",
      "Add of existing embedding ID: 159\n",
      "Insert of existing embedding ID: 160\n",
      "Add of existing embedding ID: 160\n",
      "Insert of existing embedding ID: 161\n",
      "Add of existing embedding ID: 161\n",
      "Insert of existing embedding ID: 162\n",
      "Add of existing embedding ID: 162\n",
      "Insert of existing embedding ID: 163\n",
      "Add of existing embedding ID: 163\n",
      "Insert of existing embedding ID: 164\n",
      "Add of existing embedding ID: 164\n",
      "Insert of existing embedding ID: 165\n",
      "Add of existing embedding ID: 165\n",
      "Insert of existing embedding ID: 166\n",
      "Add of existing embedding ID: 166\n",
      "Insert of existing embedding ID: 167\n",
      "Add of existing embedding ID: 167\n",
      "Insert of existing embedding ID: 168\n",
      "Add of existing embedding ID: 168\n",
      "Insert of existing embedding ID: 169\n",
      "Add of existing embedding ID: 169\n",
      "Insert of existing embedding ID: 170\n",
      "Add of existing embedding ID: 170\n",
      "Insert of existing embedding ID: 171\n",
      "Add of existing embedding ID: 171\n",
      "Insert of existing embedding ID: 172\n",
      "Add of existing embedding ID: 172\n",
      "Insert of existing embedding ID: 173\n",
      "Add of existing embedding ID: 173\n",
      "Insert of existing embedding ID: 174\n",
      "Add of existing embedding ID: 174\n",
      "Insert of existing embedding ID: 175\n",
      "Add of existing embedding ID: 175\n",
      "Insert of existing embedding ID: 176\n",
      "Add of existing embedding ID: 176\n",
      "Insert of existing embedding ID: 177\n",
      "Add of existing embedding ID: 177\n",
      "Insert of existing embedding ID: 178\n",
      "Add of existing embedding ID: 178\n",
      "Insert of existing embedding ID: 179\n",
      "Add of existing embedding ID: 179\n",
      "Insert of existing embedding ID: 180\n",
      "Add of existing embedding ID: 180\n",
      "Insert of existing embedding ID: 181\n",
      "Add of existing embedding ID: 181\n",
      "Insert of existing embedding ID: 182\n",
      "Add of existing embedding ID: 182\n",
      "Insert of existing embedding ID: 183\n",
      "Add of existing embedding ID: 183\n",
      "Insert of existing embedding ID: 184\n",
      "Add of existing embedding ID: 184\n",
      "Insert of existing embedding ID: 185\n",
      "Add of existing embedding ID: 185\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Open the JSON file\n",
    "with open(\"lectures_data.json\", \"r\") as f:\n",
    "  lectures_data = json.load(f)\n",
    "\n",
    "# Initialize OpenAI embeddings\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\",openai_api_key=openai.api_key)\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"lecture_notes\")\n",
    "# Initialize ChromaDB\n",
    "\n",
    "for idx, lecture in enumerate(lectures_data):\n",
    "    # Process text\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', lecture['text'])\n",
    "    for i,sentence in enumerate(sentences):\n",
    "      embedding = embedding_model.embed_query(sentence)\n",
    "      collection.add(\n",
    "         documents=sentence,\n",
    "         embeddings=embedding,\n",
    "         ids=[str(i)]\n",
    "      )\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['5', '82', '64', '76', '2']], 'distances': [[1.352297067642212, 1.4918099641799927, 1.5091569423675537, 1.511272668838501, 1.5145843029022217]], 'metadatas': [[None, None, None, None, None]], 'embeddings': None, 'documents': [['The classic definition of a language model (LM) is a probability distribution over sequences of tokens .', 'Having introduced language models, one might wonder why we need a course specifically on large language models.', 'Imagine the prefix: \\\\[\\\\nl{Stanford has a new course on large language models.', 'Summary Language models were first studied in the context of information theory, and can be used to estimate the entropy of English.', 'What is a language model?']], 'uris': None, 'data': None}\n"
     ]
    }
   ],
   "source": [
    "query_embedding = embedding_model.embed_query(\"What are LLM's\")\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding,\n",
    "    n_results=5  # Number of relevant results to retrieve\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classic definition of a language model (LM) is a probability distribution over sequences of tokens .\n",
      "Having introduced language models, one might wonder why we need a course specifically on large language models.\n",
      "Imagine the prefix: \\[\\nl{Stanford has a new course on large language models.\n",
      "Summary Language models were first studied in the context of information theory, and can be used to estimate the entropy of English.\n",
      "What is a language model?\n"
     ]
    }
   ],
   "source": [
    "for i in results['documents'][0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_chroma(query):\n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "    results = collection.query(\n",
    "        query_embeddings=query_embedding,\n",
    "        n_results=5  # Adjust the number of results as needed\n",
    "    )\n",
    "\n",
    "    response_parts = []\n",
    "    for doc in results['documents'][0]:\n",
    "        # metadata = res['metadata']\n",
    "        # if metadata['type'] == 'text':\n",
    "        #     response_parts.append(metadata['sentence'])\n",
    "        # elif metadata['type'] == 'link':\n",
    "        #     response_parts.append(f\"Link: {metadata['link']}\")\n",
    "        # elif metadata['type'] == 'table':\n",
    "        #     response_parts.append(f\"Table: {json.loads(metadata['table'])}\")\n",
    "        # elif metadata['type'] == 'image':\n",
    "        #     response_parts.append(f\"Image: {metadata['image']}\")\n",
    "        response_parts.append(doc)\n",
    "\n",
    "    return \" \".join(response_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    ")\n",
    "\n",
    "llm = OpenAI(temperature=0.7, model_name=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "def generate_response(context, question):\n",
    "    prompt = prompt_template.format(context=context, question=question)\n",
    "    response = llm(prompt)\n",
    "    return response\n",
    "\n",
    "\n",
    "def query_agent(query):\n",
    "    context = query_chroma(query)\n",
    "    response = generate_response(context, query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Information theory is a branch of mathematics that deals with the quantification, storage, and communication of information. It was first developed by Claude Shannon in 1948, in his paper \"A Mathematical Theory of Communication\". Shannon's work was groundbreaking as it provided a mathematical framework for understanding communication and the limits of data compression. His theory also laid the foundation for the development of various technologies such as data compression, error-correction codes, and data encryption.\n",
      "\n",
      "One of the key concepts in information theory is entropy, which measures the amount of uncertainty or randomness in a message. Shannon was particularly interested in measuring the entropy of English as a language, represented as a sequence of letters. He observed that certain letters and sequences of letters occur more frequently in English, while others are rare. Using statistical analysis, Shannon was able to estimate the entropy of English, which is approximately 1.0 to 1.5 bits per letter.\n",
      "\n",
      "In the 1950s, language models were developed as a way to improve the accuracy of machine translation and speech recognition. These models were based on n-grams, which are sequences of n words or letters. By analyzing large amounts of text, n-gram models were able to capture the statistical regularities of language and make predictions about the next word or\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me the history of Information theory, entropy of English\"\n",
    "response = query_agent(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 19:45:48.724 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\danda\\Desktop\\Ema Intern Challenge\\Emma\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-06-18 19:45:48.725 Session state does not function when running a script without `streamlit run`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator(_root_container=1, _parent=DeltaGenerator())"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.title(\"Interactive Query Bot\")\n",
    "st.write(\"Ask a question and get an answer based on the stored data.\")\n",
    "\n",
    "# Input field for the query\n",
    "query = st.text_input(\"Enter your question:\")\n",
    "\n",
    "if st.button(\"Get Answer\"):\n",
    "    with st.spinner('Generating response...'):\n",
    "        context, response = query_agent(query)\n",
    "        st.success(\"Response generated!\")\n",
    "        \n",
    "        # Display the context\n",
    "        st.subheader(\"Context:\")\n",
    "        st.write(context)\n",
    "        \n",
    "        # Display the response\n",
    "        st.subheader(\"Answer:\")\n",
    "        st.write(response)\n",
    "\n",
    "# Add additional features or customization below\n",
    "st.sidebar.title(\"About\")\n",
    "st.sidebar.info(\n",
    "    \"\"\"\n",
    "    This app uses a combination of ChromaDB, Sentence Transformers, and OpenAI's GPT-3 to \n",
    "    generate answers based on stored data. Built with Streamlit for an interactive experience.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit run c:\\Users\\danda\\Desktop\\Ema Intern Challenge\\Emma\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
