# AI-QueryBot

**AI-QueryBot** is a Question-Answering chatbot that leverages Retrieval-Augmented Generation (RAG) with large language models (LLMs). This project enables users to ask questions and receive answers generated by an LLM while retrieving relevant documents to enhance the response accuracy. It is inspired by the RAG Q-A chatbot project from Kaggle and has been extended with additional functionality, including a Gradio UI for an interactive chat experience.

## Table of Contents

1. [Overview](#overview)
2. [Features](#features)
3. [Technologies](#technologies)
4. [Installation](#installation)
5. [How It Works](#how-it-works)
6. [RAG Overview](#rag-overview)
7. [Dataset](#dataset)
9. [Contributing](#contributing)


## Overview

The goal of **AI-QueryBot** is to answer user queries by combining the strengths of pre-trained language models and a retrieval mechanism. The model first retrieves relevant documents and then generates a response by conditioning on both the query and the retrieved documents. This enables more accurate and context-aware responses.

## Features

- **Retrieval-Augmented Generation (RAG):** Combines retrieval and generation models for better question-answering.
- **LLM Integration:** Leverages large language models for natural language understanding and response generation.
- **Document Retrieval:** Retrieves relevant information from a corpus of documents to assist in answering questions.
- **Interactive UI:** Includes a Gradio-based chat UI for easy interaction with the bot.
- **Customizable Corpus:** Users can upload their own documents to create a domain-specific Q&A bot.

## Technologies

This project uses the following key technologies and frameworks:

- **Python 3.8+**
- **Transformers (Hugging Face)**: For working with pre-trained LLMs.
- **Gradio**: For building the web-based user interface.
- **LangChain**: For chaining LLMs and managing complex workflows.
- **FAISS**: For efficient document retrieval.
- **Pandas**: For data processing.
- **PyTorch**: As the backend for training and fine-tuning models.

## Installation

To set up **AI-QueryBot** locally, follow these steps:

### 1. Clone the Repository
```bash
git clone https://github.com/S1ayer2602/AI-QueryBot.git
cd AI-QueryBot
```
### 2. Create a Virtual Environment
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
```
### 3. Install Dependencies
```bash
pip install -r requirements.txt

```

## How It Works
- **Question Processing**: The user submits a question, which is processed by the language model.
- **Document Retrieval**: A search is performed over the document corpus using FAISS (or another retrieval mechanism), retrieving the most relevant documents related to the question.
- **Answer Generation**: The model generates a response by combining the user query with the retrieved documents. This is where RAG (Retrieval-Augmented Generation) comes into play.
- **Interactive UI**: The answer is displayed in the chat UI, along with any relevant supporting documents.
## RAG Overview
- **Retrieval Component**: FAISS or another vector store is used to fetch relevant documents from the document index based on the query.
- **Generation Component**: A pre-trained LLM is used to generate a response, conditioned on the query and the retrieved documents.

## Dataset
The current version uses publicly available datasets (e.g., from Wikipedia or similar sources), but it is fully customizable. You can upload your own documents for domain-specific QA.

## Contributing
Contributions are welcome! If you have ideas for new features or find bugs, feel free to open an issue or submit a pull request.
